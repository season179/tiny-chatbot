# Create a model response

`POST https://api.openai.com/v1/responses`

Creates a model response. Provide [text](/docs/guides/text) or [image](/docs/guides/images) inputs to generate [text](/docs/guides/text) or [JSON](/docs/guides/structured-outputs) outputs. Have the model call your own [custom code](/docs/guides/function-calling) or use built-in [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search) to use your own data as input for the model's response.

## Request body

### background
- Type: boolean
- Optional
- Defaults to false

Whether to run the model response in the background. [Learn more](/docs/guides/background).

### conversation
- Type: string or object
- Optional
- Defaults to null

The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request. Input items and output items from this response are automatically added to this conversation after this response completes.

#### Conversation ID
- Type: string

The unique ID of the conversation.

#### Conversation object
- Type: object

The conversation that this response belongs to.

##### id
- Type: string
- Required

The unique ID of the conversation.

### include
- Type: array
- Optional

Specify additional output data to include in the model response. Currently supported values are:

* `web_search_call.action.sources`: Include the sources of the web search tool call.
* `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.
* `computer_call_output.output.image_url`: Include image urls from the computer call output.
* `file_search_call.results`: Include the search results of the file search tool call.
* `message.input_image.image_url`: Include image urls from the input message.
* `message.output_text.logprobs`: Include logprobs with assistant messages.
* `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).

### input
- Type: string or array
- Optional

Text, image, or file inputs to the model, used to generate a response.

Learn more:

* [Text inputs and outputs](/docs/guides/text)
* [Image inputs](/docs/guides/images)
* [File inputs](/docs/guides/pdf-files)
* [Conversation state](/docs/guides/conversation-state)
* [Function calling](/docs/guides/function-calling)

#### Text input
- Type: string

A text input to the model, equivalent to a text input with the `user` role.

#### Input item list
- Type: array

A list of one or many input items to the model, containing different content types.

##### Input message
- Type: object

A message input to the model with a role indicating instruction following hierarchy. Instructions given with the `developer` or `system` role take precedence over instructions given with the `user` role. Messages with the `assistant` role are presumed to have been generated by the model in previous interactions.

###### content
- Type: string or array
- Required

Text, image, or audio input to the model, used to generate a response. Can also contain previous assistant responses.

###### Text input
- Type: string

A text input to the model.

###### Input item content list
- Type: array

A list of one or many input items to the model, containing different content types.

###### Input text
- Type: object

A text input to the model.

###### Input image
- Type: object

An image input to the model. Learn about [image inputs](/docs/guides/vision).

###### Input file
- Type: object

A file input to the model.

###### Input audio
- Type: object

An audio input to the model.

###### role
- Type: string
- Required

The role of the message input. One of `user`, `assistant`, `system`, or `developer`.

###### type
- Type: string
- Optional

The type of the message input. Always `message`.

##### Item
- Type: object

An item representing part of the context for the response to be generated by the model. Can contain text, images, and audio inputs, as well as previous assistant responses and tool call outputs.

###### Input message
- Type: object

A message input to the model with a role indicating instruction following hierarchy. Instructions given with the `developer` or `system` role take precedence over instructions given with the `user` role.

###### content
- Type: array
- Required

A list of one or many input items to the model, containing different content types.

###### Input text
- Type: object

A text input to the model.

###### text
- Type: string
- Required

The text input to the model.

###### type
- Type: string
- Required

The type of the input item. Always `input_text`.

###### Input image
- Type: object

An image input to the model. Learn about [image inputs](/docs/guides/vision).

###### detail
- Type: string
- Required

The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.

###### type
- Type: string
- Required

The type of the input item. Always `input_image`.

###### file_id
- Type: string
- Optional

The ID of the file to be sent to the model.

###### image_url
- Type: string
- Optional

The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.

###### Input file
- Type: object

A file input to the model.

###### type
- Type: string
- Required

The type of the input item. Always `input_file`.

###### file_data
- Type: string
- Optional

The content of the file to be sent to the model.

###### file_id
- Type: string
- Optional

The ID of the file to be sent to the model.

###### file_url
- Type: string
- Optional

The URL of the file to be sent to the model.

###### filename
- Type: string
- Optional

The name of the file to be sent to the model.

###### Input audio
- Type: object

An audio input to the model.

###### input_audio
- Type: object
- Required

###### data
- Type: string
- Required

Base64-encoded audio data.

###### format
- Type: string
- Required

The format of the audio data. Currently supported formats are `mp3` and `wav`.

###### type
- Type: string
- Required

The type of the input item. Always `input_audio`.

###### role
- Type: string
- Required

The role of the message input. One of `user`, `system`, or `developer`.

###### status
- Type: string
- Optional

The status of item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.

###### type
- Type: string
- Optional

The type of the message input. Always set to `message`.

###### Output message
- Type: object

An output message from the model.

###### content
- Type: array
- Required

The content of the output message.

###### Output text
- Type: object

A text output from the model.

###### annotations
- Type: array
- Required

The annotations of the text output.

###### File citation
- Type: object

A citation to a file.

###### file_id
- Type: string
- Required

The ID of the file.

###### filename
- Type: string
- Required

The filename of the file cited.

###### index
- Type: integer
- Required

The index of the file in the list of files.

###### type
- Type: string
- Required

The type of the file citation. Always `file_citation`.

###### URL citation
- Type: object

A citation for a web resource used to generate a model response.

###### end_index
- Type: integer
- Required

The index of the last character of the URL citation in the message.

###### start_index
- Type: integer
- Required

The index of the first character of the URL citation in the message.

###### title
- Type: string
- Required

The title of the web resource.

###### type
- Type: string
- Required

The type of the URL citation. Always `url_citation`.

###### url
- Type: string
- Required

The URL of the web resource.

###### Container file citation
- Type: object

A citation for a container file used to generate a model response.

###### container_id
- Type: string
- Required

The ID of the container file.

###### end_index
- Type: integer
- Required

The index of the last character of the container file citation in the message.

###### file_id
- Type: string
- Required

The ID of the file.

###### filename
- Type: string
- Required

The filename of the container file cited.

###### start_index
- Type: integer
- Required

The index of the first character of the container file citation in the message.

###### type
- Type: string
- Required

The type of the container file citation. Always `container_file_citation`.

###### File path
- Type: object

A path to a file.

###### file_id
- Type: string
- Required

The ID of the file.

###### index
- Type: integer
- Required

The index of the file in the list of files.

###### type
- Type: string
- Required

The type of the file path. Always `file_path`.

###### text
- Type: string
- Required

The text output from the model.

###### type
- Type: string
- Required

The type of the output text. Always `output_text`.

###### logprobs
- Type: array
- Optional

###### bytes
- Type: array
- Required

###### logprob
- Type: number
- Required

###### token
- Type: string
- Required

###### top_logprobs
- Type: array
- Required

###### bytes
- Type: array
- Required

###### logprob
- Type: number
- Required

###### token
- Type: string
- Required

###### Refusal
- Type: object

A refusal from the model.

###### refusal
- Type: string
- Required

The refusal explanation from the model.

###### type
- Type: string
- Required

The type of the refusal. Always `refusal`.

###### id
- Type: string
- Required

The unique ID of the output message.

###### role
- Type: string
- Required

The role of the output message. Always `assistant`.

###### status
- Type: string
- Required

The status of the message input. One of `in_progress`, `completed`, or `incomplete`. Populated when input items are returned via API.

###### type
- Type: string
- Required

The type of the output message. Always `message`.

###### File search tool call
- Type: object

The results of a file search tool call. See the [file search guide](/docs/guides/tools-file-search) for more information.

###### id
- Type: string
- Required

The unique ID of the file search tool call.

###### queries
- Type: array
- Required

The queries used to search for files.

###### status
- Type: string
- Required

The status of the file search tool call. One of `in_progress`, `searching`, `incomplete` or `failed`,

###### type
- Type: string
- Required

The type of the file search tool call. Always `file_search_call`.

###### results
- Type: array
- Optional

The results of the file search tool call.

###### attributes
- Type: map
- Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

###### file_id
- Type: string
- Optional

The unique ID of the file.

###### filename
- Type: string
- Optional

The name of the file.

###### score
- Type: number
- Optional

The relevance score of the file - a value between 0 and 1.

###### text
- Type: string
- Optional

The text that was retrieved from the file.

###### Computer tool call
- Type: object

A tool call to a computer use tool. See the [computer use guide](/docs/guides/tools-computer-use) for more information.

###### action
- Type: object
- Required

###### Click
- Type: object

A click action.

###### button
- Type: string
- Required

Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`.

###### type
- Type: string
- Required

Specifies the event type. For a click action, this property is always set to `click`.

###### x
- Type: integer
- Required

The x-coordinate where the click occurred.

###### y
- Type: integer
- Required

The y-coordinate where the click occurred.

###### DoubleClick
- Type: object

A double click action.

###### type
- Type: string
- Required

Specifies the event type. For a double click action, this property is always set to `double_click`.

###### x
- Type: integer
- Required

The x-coordinate where the double click occurred.

###### y
- Type: integer
- Required

The y-coordinate where the double click occurred.

###### Drag
- Type: object

A drag action.

###### path
- Type: array
- Required

An array of coordinates representing the path of the drag action. Coordinates will appear as an array of objects, eg

```
1
2
3
4
[
  { x: 100, y: 200 },
  { x: 200, y: 300 }
]
```

###### x
- Type: integer
- Required

The x-coordinate.

###### y
- Type: integer
- Required

The y-coordinate.

###### type
- Type: string
- Required

Specifies the event type. For a drag action, this property is always set to `drag`.

###### KeyPress
- Type: object

A collection of keypresses the model would like to perform.

###### keys
- Type: array
- Required

The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.

###### type
- Type: string
- Required

Specifies the event type. For a keypress action, this property is always set to `keypress`.

###### Move
- Type: object

A mouse move action.

###### type
- Type: string
- Required

Specifies the event type. For a move action, this property is always set to `move`.

###### x
- Type: integer
- Required

The x-coordinate to move to.

###### y
- Type: integer
- Required

The y-coordinate to move to.

###### Screenshot
- Type: object

A screenshot action.

###### type
- Type: string
- Required

Specifies the event type. For a screenshot action, this property is always set to `screenshot`.

###### Scroll
- Type: object

A scroll action.

###### scroll_x
- Type: integer
- Required

The horizontal scroll distance.

###### scroll_y
- Type: integer
- Required

The vertical scroll distance.

###### type
- Type: string
- Required

Specifies the event type. For a scroll action, this property is always set to `scroll`.

###### x
- Type: integer
- Required

The x-coordinate where the scroll occurred.

###### y
- Type: integer
- Required

The y-coordinate where the scroll occurred.

###### Type
- Type: object

An action to type in text.

###### text
- Type: string
- Required

The text to type.

###### type
- Type: string
- Required

Specifies the event type. For a type action, this property is always set to `type`.

###### Wait
- Type: object

A wait action.

###### type
- Type: string
- Required

Specifies the event type. For a wait action, this property is always set to `wait`.

###### call_id
- Type: string
- Required

An identifier used when responding to the tool call with output.

###### id
- Type: string
- Required

The unique ID of the computer call.

###### pending_safety_checks
- Type: array
- Required

The pending safety checks for the computer call.

###### code
- Type: string
- Required

The type of the pending safety check.

###### id
- Type: string
- Required

The ID of the pending safety check.

###### message
- Type: string
- Required

Details about the pending safety check.

###### status
- Type: string
- Required

The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.

###### type
- Type: string
- Required

The type of the computer call. Always `computer_call`.

###### Computer tool call output
- Type: object

The output of a computer tool call.

###### call_id
- Type: string
- Required

The ID of the computer tool call that produced the output.

###### output
- Type: object
- Required

A computer screenshot image used with the computer use tool.

###### type
- Type: string
- Required

Specifies the event type. For a computer screenshot, this property is always set to `computer_screenshot`.

###### file_id
- Type: string
- Optional

The identifier of an uploaded file that contains the screenshot.

###### image_url
- Type: string
- Optional

The URL of the screenshot image.

###### type
- Type: string
- Required

The type of the computer tool call output. Always `computer_call_output`.

###### acknowledged_safety_checks
- Type: array
- Optional

The safety checks reported by the API that have been acknowledged by the developer.

###### id
- Type: string
- Required

The ID of the pending safety check.

###### code
- Type: string
- Optional

The type of the pending safety check.

###### message
- Type: string
- Optional

Details about the pending safety check.

###### id
- Type: string
- Optional

The ID of the computer tool call output.

###### status
- Type: string
- Optional

The status of the message input. One of `in_progress`, `completed`, or `incomplete`. Populated when input items are returned via API.

###### Web search tool call
- Type: object

The results of a web search tool call. See the [web search guide](/docs/guides/tools-web-search) for more information.

###### action
- Type: object
- Required

An object describing the specific action taken in this web search call. Includes details on how the model used the web (search, open\_page, find).

###### Search action
- Type: object

Action type "search" - Performs a web search query.

###### query
- Type: string
- Required

The search query.

###### type
- Type: string
- Required

The action type.

###### sources
- Type: array
- Optional

The sources used in the search.

###### type
- Type: string
- Required

The type of source. Always `url`.

###### url
- Type: string
- Required

The URL of the source.

###### Open page action
- Type: object

Action type "open\_page" - Opens a specific URL from search results.

###### type
- Type: string
- Required

The action type.

###### url
- Type: string
- Required

The URL opened by the model.

###### Find action
- Type: object

Action type "find": Searches for a pattern within a loaded page.

###### pattern
- Type: string
- Required

The pattern or text to search for within the page.

###### type
- Type: string
- Required

The action type.

###### url
- Type: string
- Required

The URL of the page searched for the pattern.

###### id
- Type: string
- Required

The unique ID of the web search tool call.

###### status
- Type: string
- Required

The status of the web search tool call.

###### type
- Type: string
- Required

The type of the web search tool call. Always `web_search_call`.

###### Function tool call
- Type: object

A tool call to run a function. See the [function calling guide](/docs/guides/function-calling) for more information.

###### arguments
- Type: string
- Required

A JSON string of the arguments to pass to the function.

###### call_id
- Type: string
- Required

The unique ID of the function tool call generated by the model.

###### name
- Type: string
- Required

The name of the function to run.

###### type
- Type: string
- Required

The type of the function tool call. Always `function_call`.

###### id
- Type: string
- Optional

The unique ID of the function tool call.

###### status
- Type: string
- Optional

The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.

###### Function tool call output
- Type: object

The output of a function tool call.

###### call_id
- Type: string
- Required

The unique ID of the function tool call generated by the model.

###### output
- Type: string or array
- Required

Text, image, or file output of the function tool call.

###### string
A JSON string of the output of the function tool call.

###### array

###### Input text
- Type: object

A text input to the model.

###### text
- Type: string
- Required

The text input to the model.

###### type
- Type: string
- Required

The type of the input item. Always `input_text`.

###### Input image
- Type: object

An image input to the model. Learn about [image inputs](/docs/guides/vision)

###### type
- Type: string
- Required

The type of the input item. Always `input_image`.

###### detail
- Type: string
- Optional

The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.

###### file_id
- Type: string
- Optional

The ID of the file to be sent to the model.

###### image_url
- Type: string
- Optional

The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.

###### Input file
- Type: object

A file input to the model.

###### type
- Type: string
- Required

The type of the input item. Always `input_file`.

###### file_data
- Type: string
- Optional

The base64-encoded data of the file to be sent to the model.

###### file_id
- Type: string
- Optional

The ID of the file to be sent to the model.

###### file_url
- Type: string
- Optional

The URL of the file to be sent to the model.

###### filename
- Type: string
- Optional

The name of the file to be sent to the model.

###### type
- Type: string
- Required

The type of the function tool call output. Always `function_call_output`.

###### id
- Type: string
- Optional

The unique ID of the function tool call output. Populated when this item is returned via API.

###### status
- Type: string
- Optional

The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.

###### Reasoning
- Type: object

A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your `input` to the Responses API for subsequent turns of a conversation if you are manually [managing context](/docs/guides/conversation-state).

###### id
- Type: string
- Required

The unique identifier of the reasoning content.

###### summary
- Type: array
- Required

Reasoning summary content.

###### text
- Type: string
- Required

A summary of the reasoning output from the model so far.

###### type
- Type: string
- Required

The type of the object. Always `summary_text`.

###### type
- Type: string
- Required

The type of the object. Always `reasoning`.

###### content
- Type: array
- Optional

Reasoning text content.

###### text
- Type: string
- Required

The reasoning text from the model.

###### type
- Type: string
- Required

The type of the reasoning text. Always `reasoning_text`.

###### encrypted_content
- Type: string
- Optional

The encrypted content of the reasoning item - populated when a response is generated with `reasoning.encrypted_content` in the `include` parameter.

###### status
- Type: string
- Optional

The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.

###### Image generation call
- Type: object

An image generation request made by the model.

###### id
- Type: string
- Required

The unique ID of the image generation call.

###### result
- Type: string
- Required

The generated image encoded in base64.

###### status
- Type: string
- Required

The status of the image generation call.

###### type
- Type: string
- Required

The type of the image generation call. Always `image_generation_call`.

###### Code interpreter tool call
- Type: object

A tool call to run code.

###### code
- Type: string
- Required

The code to run, or null if not available.

###### container_id
- Type: string
- Required

The ID of the container used to run the code.

###### id
- Type: string
- Required

The unique ID of the code interpreter tool call.

###### outputs
- Type: array
- Required

The outputs generated by the code interpreter, such as logs or images. Can be null if no outputs are available.

###### status
- Type: string
- Required

The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.

###### type
- Type: string
- Required

The type of the code interpreter tool call. Always `code_interpreter_call`.

###### Local shell call
- Type: object

A tool call to run a command on the local shell.

###### action
- Type: object
- Required

Execute a shell command on the server.

###### call_id
- Type: string
- Required

The unique ID of the local shell tool call generated by the model.

###### id
- Type: string
- Required

The unique ID of the local shell call.

###### status
- Type: string
- Required

The status of the local shell call.

###### type
- Type: string
- Required

The type of the local shell call. Always `local_shell_call`.

###### Local shell call output
- Type: object

The output of a local shell tool call.

###### id
- Type: string
- Required

The unique ID of the local shell tool call generated by the model.

###### output
- Type: string
- Required

A JSON string of the output of the local shell tool call.

###### type
- Type: string
- Required

The type of the local shell tool call output. Always `local_shell_call_output`.

###### status
- Type: string
- Optional

The status of the item. One of `in_progress`, `completed`, or `incomplete`.

###### MCP list tools
- Type: object

A list of tools available on an MCP server.

###### id
- Type: string
- Required

The unique ID of the list.

###### server_label
- Type: string
- Required

The label of the MCP server.

###### tools
- Type: array
- Required

The tools available on the server.

###### type
- Type: string
- Required

The type of the item. Always `mcp_list_tools`.

###### error
- Type: string
- Optional

Error message if the server could not list tools.

###### MCP approval request
- Type: object

A request for human approval of a tool invocation.

###### arguments
- Type: string
- Required

A JSON string of arguments for the tool.

###### id
- Type: string
- Required

The unique ID of the approval request.

###### name
- Type: string
- Required

The name of the tool to run.

###### server_label
- Type: string
- Required

The label of the MCP server making the request.

###### type
- Type: string
- Required

The type of the item. Always `mcp_approval_request`.

###### MCP approval response
- Type: object

A response to an MCP approval request.

###### approval_request_id
- Type: string
- Required

The ID of the approval request being answered.

###### approve
- Type: boolean
- Required

Whether the request was approved.

###### type
- Type: string
- Required

The type of the item. Always `mcp_approval_response`.

###### id
- Type: string
- Optional

The unique ID of the approval response

###### reason
- Type: string
- Optional

Optional reason for the decision.

###### MCP tool call
- Type: object

An invocation of a tool on an MCP server.

###### arguments
- Type: string
- Required

A JSON string of the arguments passed to the tool.

###### id
- Type: string
- Required

The unique ID of the tool call.

###### name
- Type: string
- Required

The name of the tool that was run.

###### server_label
- Type: string
- Required

The label of the MCP server running the tool.

###### type
- Type: string
- Required

The type of the item. Always `mcp_call`.

###### error
- Type: string
- Optional

The error from the tool call, if any.

###### output
- Type: string
- Optional

The output from the tool call.

###### Custom tool call output
- Type: object

The output of a custom tool call from your code, being sent back to the model.

###### call_id
- Type: string
- Required

The call ID, used to map this custom tool call output to a custom tool call.

###### output
- Type: string or array
- Required

The output from the custom tool call generated by your code. Can be a string or an list of output content.

###### type
- Type: string
- Required

The type of the custom tool call output. Always `custom_tool_call_output`.

###### id
- Type: string
- Optional

The unique ID of the custom tool call output in the OpenAI platform.

###### Custom tool call
- Type: object

A call to a custom tool created by the model.

###### call_id
- Type: string
- Required

An identifier used to map this custom tool call to a tool call output.

###### input
- Type: string
- Required

The input for the custom tool call generated by the model.

###### name
- Type: string
- Required

The name of the custom tool being called.

###### type
- Type: string
- Required

The type of the custom tool call. Always `custom_tool_call`.

###### id
- Type: string
- Optional

The unique ID of the custom tool call in the OpenAI platform.

##### Item reference
- Type: object

An internal identifier for an item to reference.

###### id
- Type: string
- Required

The ID of the item to reference.

###### type
- Type: string
- Optional
- Defaults to item_reference

The type of item to reference. Always `item_reference`.

### instructions
- Type: string
- Optional

A system (or developer) message inserted into the model's context.

When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

### max_output_tokens
- Type: integer
- Optional

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

### max_tool_calls
- Type: integer
- Optional

The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.

### metadata
- Type: map
- Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

### model
- Type: string
- Optional

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

### parallel_tool_calls
- Type: boolean
- Optional
- Defaults to true

Whether to allow the model to run tool calls in parallel.

### previous_response_id
- Type: string
- Optional

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.

### prompt
- Type: object
- Optional

Reference to a prompt template and its variables. [Learn more](/docs/guides/text?api-mode=responses#reusable-prompts).

#### id
- Type: string
- Required

The unique identifier of the prompt template to use.

#### variables
- Type: map
- Optional

Optional map of values to substitute in for variables in your prompt. The substitution values can either be strings, or other Response input types like images or files.

#### version
- Type: string
- Optional

Optional version of the prompt template.

### prompt_cache_key
- Type: string
- Optional

Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](/docs/guides/prompt-caching).

### reasoning
- Type: object
- Optional

**gpt-5 and o-series models only**

Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).

#### effort
- Type: string
- Optional
- Defaults to medium

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

#### generate_summary
- Type: string
- Optional
- Deprecated

**Deprecated:** use `summary` instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of `auto`, `concise`, or `detailed`.

#### summary
- Type: string
- Optional

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of `auto`, `concise`, or `detailed`.

### safety_identifier
- Type: string
- Optional

A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](/docs/guides/safety-best-practices#safety-identifiers).

### service_tier
- Type: string
- Optional
- Defaults to auto

Specifies the processing type used for serving the request.

* If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
* If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
* If set to '[flex](/docs/guides/flex-processing)' or '[priority](https://openai.com/api-priority-processing/)', then the request will be processed with the corresponding service tier.
* When not set, the default behavior is 'auto'.

When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.

### store
- Type: boolean
- Optional
- Defaults to true

Whether to store the generated model response for later retrieval via API.

### stream
- Type: boolean
- Optional
- Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](/docs/api-reference/responses-streaming) for more information.

### stream_options
- Type: object
- Optional
- Defaults to null

Options for streaming responses. Only set this when you set `stream: true`.

#### include_obfuscation
- Type: boolean
- Optional

When true, stream obfuscation will be enabled. Stream obfuscation adds random characters to an `obfuscation` field on streaming delta events to normalize payload sizes as a mitigation to certain side-channel attacks. These obfuscation fields are included by default, but add a small amount of overhead to the data stream. You can set `include_obfuscation` to false to optimize for bandwidth if you trust the network links between your application and the OpenAI API.

### temperature
- Type: number
- Optional
- Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

### text
- Type: object
- Optional

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

* [Text inputs and outputs](/docs/guides/text)
* [Structured Outputs](/docs/guides/structured-outputs)

#### format
- Type: object
- Optional

An object specifying the format that the model must output.

Configuring `{ "type": "json_schema" }` enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

The default format is `{ "type": "text" }` with no additional options.

**Not recommended for gpt-4o and newer models:**

Setting to `{ "type": "json_object" }` enables the older JSON mode, which ensures the message the model generates is valid JSON. Using `json_schema` is preferred for models that support it.

#### verbosity
- Type: string
- Optional
- Defaults to medium

Constrains the verbosity of the model's response. Lower values will result in more concise responses, while higher values will result in more verbose responses. Currently supported values are `low`, `medium`, and `high`.

### tool_choice
- Type: string or object
- Optional

How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.

#### Tool choice mode
- Type: string

Controls which (if any) tool is called by the model.

`none` means the model will not call any tool and instead generates a message.

`auto` means the model can pick between generating a message or calling one or more tools.

`required` means the model must call one or more tools.

#### Allowed tools
- Type: object

Constrains the tools available to the model to a pre-defined set.

##### mode
- Type: string
- Required

Constrains the tools available to the model to a pre-defined set.

`auto` allows the model to pick from among the allowed tools and generate a message.

`required` requires the model to call one or more of the allowed tools.

##### tools
- Type: array
- Required

A list of tool definitions that the model should be allowed to call.

For the Responses API, the list of tool definitions might look like:

```
1
2
3
4
5
[
  { "type": "function", "name": "get_weather" },
  { "type": "mcp", "server_label": "deepwiki" },
  { "type": "image_generation" }
]
```

##### type
- Type: string
- Required

Allowed tool configuration type. Always `allowed_tools`.

#### Hosted tool
- Type: object

Indicates that the model should use a built-in tool to generate a response. [Learn more about built-in tools](/docs/guides/tools).

##### type
- Type: string
- Required

The type of hosted tool the model should to use. Learn more about [built-in tools](/docs/guides/tools).

Allowed values are:

* `file_search`
* `web_search_preview`
* `computer_use_preview`
* `code_interpreter`
* `image_generation`

#### Function tool
- Type: object

Use this option to force the model to call a specific function.

##### name
- Type: string
- Required

The name of the function to call.

##### type
- Type: string
- Required

For function calling, the type is always `function`.

#### MCP tool
- Type: object

Use this option to force the model to call a specific tool on a remote MCP server.

##### server_label
- Type: string
- Required

The label of the MCP server to use.

##### type
- Type: string
- Required

For MCP tools, the type is always `mcp`.

##### name
- Type: string
- Optional

The name of the tool to call on the server.

#### Custom tool
- Type: object

Use this option to force the model to call a specific custom tool.

##### name
- Type: string
- Required

The name of the custom tool to call.

##### type
- Type: string
- Required

For custom tool calling, the type is always `custom`.

### tools
- Type: array
- Optional

An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

We support the following categories of tools:

* **Built-in tools**: Tools that are provided by OpenAI that extend the model's capabilities, like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search). Learn more about [built-in tools](/docs/guides/tools).
* **MCP Tools**: Integrations with third-party systems via custom MCP servers or predefined connectors such as Google Drive and SharePoint. Learn more about [MCP Tools](/docs/guides/tools-connectors-mcp).
* **Function calls (custom tools)**: Functions that are defined by you, enabling the model to call your own code with strongly typed arguments and outputs. Learn more about [function calling](/docs/guides/function-calling). You can also use custom tools to call your own code.

#### Function
- Type: object

Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).

##### name
- Type: string
- Required

The name of the function to call.

##### parameters
- Type: object
- Required

A JSON schema object describing the parameters of the function.

##### strict
- Type: boolean
- Required

Whether to enforce strict parameter validation. Default `true`.

##### type
- Type: string
- Required

The type of the function tool. Always `function`.

##### description
- Type: string
- Optional

A description of the function. Used by the model to determine whether or not to call the function.

#### File search
- Type: object

A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).

##### type
- Type: string
- Required

The type of the file search tool. Always `file_search`.

##### vector_store_ids
- Type: array
- Required

The IDs of the vector stores to search.

##### filters
- Type: object
- Optional

A filter to apply.

###### Comparison Filter
- Type: object

A filter used to compare a specified attribute key to a given value using a defined comparison operation.

###### key
- Type: string
- Required

The key to compare against the value.

###### type
- Type: string
- Required

Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.

* `eq`: equals
* `ne`: not equal
* `gt`: greater than
* `gte`: greater than or equal
* `lt`: less than
* `lte`: less than or equal

###### value
- Type: string / number / boolean
- Required

The value to compare against the attribute key; supports string, number, or boolean types.

###### Compound Filter
- Type: object

Combine multiple filters using `and` or `or`.

###### filters
- Type: array
- Required

Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.

###### Comparison Filter
- Type: object

A filter used to compare a specified attribute key to a given value using a defined comparison operation.

###### key
- Type: string
- Required

The key to compare against the value.

###### type
- Type: string
- Required

Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.

* `eq`: equals
* `ne`: not equal
* `gt`: greater than
* `gte`: greater than or equal
* `lt`: less than
* `lte`: less than or equal

###### value
- Type: string / number / boolean
- Required

The value to compare against the attribute key; supports string, number, or boolean types.

###### type
- Type: string
- Required

Type of operation: `and` or `or`.

##### max_num_results
- Type: integer
- Optional

The maximum number of results to return. This number should be between 1 and 50 inclusive.

##### ranking_options
- Type: object
- Optional

Ranking options for search.

###### ranker
- Type: string
- Optional

The ranker to use for the file search.

###### score_threshold
- Type: number
- Optional

The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.

#### Computer use preview
- Type: object

A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).

##### display_height
- Type: integer
- Required

The height of the computer display.

##### display_width
- Type: integer
- Required

The width of the computer display.

##### environment
- Type: string
- Required

The type of computer environment to control.

##### type
- Type: string
- Required

The type of the computer use tool. Always `computer_use_preview`.

#### Web search
- Type: object

Search the Internet for sources related to the prompt. Learn more about the [web search tool](/docs/guides/tools-web-search).

##### type
- Type: string
- Required

The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.

##### filters
- Type: object
- Optional

Filters for the search.

###### allowed_domains
- Type: array
- Optional
- Defaults to []

Allowed domains for the search. If not provided, all domains are allowed. Subdomains of the provided domains are allowed as well.

Example: `["pubmed.ncbi.nlm.nih.gov"]`

##### search_context_size
- Type: string
- Optional
- Defaults to medium

High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.

##### user_location
- Type: object
- Optional

The approximate location of the user.

###### city
- Type: string
- Optional

Free text input for the city of the user, e.g. `San Francisco`.

###### country
- Type: string
- Optional

The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.

###### region
- Type: string
- Optional

Free text input for the region of the user, e.g. `California`.

###### timezone
- Type: string
- Optional

The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.

###### type
- Type: string
- Optional
- Defaults to approximate

The type of location approximation. Always `approximate`.

#### MCP tool
- Type: object

Give the model access to additional tools via remote Model Context Protocol (MCP) servers. [Learn more about MCP](/docs/guides/tools-remote-mcp).

##### server_label
- Type: string
- Required

A label for this MCP server, used to identify it in tool calls.

##### type
- Type: string
- Required

The type of the MCP tool. Always `mcp`.

##### allowed_tools
- Type: array or object
- Optional

List of allowed tool names or a filter object.

###### MCP allowed tools
- Type: array

A string array of allowed tool names

###### MCP tool filter
- Type: object

A filter object to specify which tools are allowed.

###### read_only
- Type: boolean
- Optional

Indicates whether or not a tool modifies data or is read-only. If an MCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint), it will match this filter.

###### tool_names
- Type: array
- Optional

List of allowed tool names.

##### authorization
- Type: string
- Optional

An OAuth access token that can be used with a remote MCP server, either with a custom MCP server URL or a service connector. Your application must handle the OAuth authorization flow and provide the token here.

##### connector_id
- Type: string
- Optional

Identifier for service connectors, like those available in ChatGPT. One of `server_url` or `connector_id` must be provided. Learn more about service connectors [here](/docs/guides/tools-remote-mcp#connectors).

Currently supported `connector_id` values are:

* Dropbox: `connector_dropbox`
* Gmail: `connector_gmail`
* Google Calendar: `connector_googlecalendar`
* Google Drive: `connector_googledrive`
* Microsoft Teams: `connector_microsoftteams`
* Outlook Calendar: `connector_outlookcalendar`
* Outlook Email: `connector_outlookemail`
* SharePoint: `connector_sharepoint`

##### headers
- Type: object
- Optional

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

##### require_approval
- Type: object or string
- Optional
- Defaults to always

Specify which of the MCP server's tools require approval.

###### MCP tool approval filter
- Type: object

Specify which of the MCP server's tools require approval. Can be `always`, `never`, or a filter object associated with tools that require approval.

###### always
- Type: object
- Optional

A filter object to specify which tools are allowed.

###### read_only
- Type: boolean
- Optional

Indicates whether or not a tool modifies data or is read-only. If an MCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint), it will match this filter.

###### tool_names
- Type: array
- Optional

List of allowed tool names.

###### never
- Type: object
- Optional

A filter object to specify which tools are allowed.

###### read_only
- Type: boolean
- Optional

Indicates whether or not a tool modifies data or is read-only. If an MCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint), it will match this filter.

###### tool_names
- Type: array
- Optional

List of allowed tool names.

###### MCP tool approval setting
- Type: string

Specify a single approval policy for all tools. One of `always` or `never`. When set to `always`, all tools will require approval. When set to `never`, all tools will not require approval.

##### server_description
- Type: string
- Optional

Optional description of the MCP server, used to provide more context.

##### server_url
- Type: string
- Optional

The URL for the MCP server. One of `server_url` or `connector_id` must be provided.

#### Code interpreter
- Type: object

A tool that runs Python code to help generate a response to a prompt.

##### container
- Type: string or object
- Required

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.

###### string
The container ID.

###### CodeInterpreterContainerAuto
- Type: object

Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.

###### type
- Type: string
- Required

Always `auto`.

###### file_ids
- Type: array
- Optional

An optional list of uploaded files to make available to your code.

##### type
- Type: string
- Required

The type of the code interpreter tool. Always `code_interpreter`.

#### Image generation tool
- Type: object

A tool that generates images using a model like `gpt-image-1`.

##### type
- Type: string
- Required

The type of the image generation tool. Always `image_generation`.

##### background
- Type: string
- Optional
- Defaults to auto

Background type for the generated image. One of `transparent`, `opaque`, or `auto`. Default: `auto`.

##### input_fidelity
- Type: string
- Optional
- Defaults to low

Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Supports `high` and `low`. Defaults to `low`.

##### input_image_mask
- Type: object
- Optional

Optional mask for inpainting. Contains `image_url` (string, optional) and `file_id` (string, optional).

###### file_id
- Type: string
- Optional

File ID for the mask image.

###### image_url
- Type: string
- Optional

Base64-encoded mask image.

##### model
- Type: string
- Optional
- Defaults to gpt-image-1

The image generation model to use. Default: `gpt-image-1`.

##### moderation
- Type: string
- Optional
- Defaults to auto

Moderation level for the generated image. Default: `auto`.

##### output_compression
- Type: integer
- Optional
- Defaults to 100

Compression level for the output image. Default: 100.

##### output_format
- Type: string
- Optional
- Defaults to png

The output format of the generated image. One of `png`, `webp`, or `jpeg`. Default: `png`.

##### partial_images
- Type: integer
- Optional
- Defaults to 0

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

##### quality
- Type: string
- Optional
- Defaults to auto

The quality of the generated image. One of `low`, `medium`, `high`, or `auto`. Default: `auto`.

##### size
- Type: string
- Optional
- Defaults to auto

The size of the generated image. One of `1024x1024`, `1024x1536`, `1536x1024`, or `auto`. Default: `auto`.

#### Local shell tool
- Type: object

A tool that allows the model to execute shell commands in a local environment.

##### type
- Type: string
- Required

The type of the local shell tool. Always `local_shell`.

#### Custom tool
- Type: object

A custom tool that processes input using a specified format. Learn more about [custom tools](/docs/guides/function-calling#custom-tools).

##### name
- Type: string
- Required

The name of the custom tool, used to identify it in tool calls.

##### type
- Type: string
- Required

The type of the custom tool. Always `custom`.

##### description
- Type: string
- Optional

Optional description of the custom tool, used to provide more context.

##### format
- Type: object
- Optional

The input format for the custom tool. Default is unconstrained text.

###### Text format
- Type: object

Unconstrained free-form text.

###### Grammar format
- Type: object

A grammar defined by the user.

#### Web search preview
- Type: object

This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).

##### type
- Type: string
- Required

The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.

##### search_context_size
- Type: string
- Optional

High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.

##### user_location
- Type: object
- Optional

The user's location.

###### type
- Type: string
- Required

The type of location approximation. Always `approximate`.

###### city
- Type: string
- Optional

Free text input for the city of the user, e.g. `San Francisco`.

###### country
- Type: string
- Optional

The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.

###### region
- Type: string
- Optional

Free text input for the region of the user, e.g. `California`.

###### timezone
- Type: string
- Optional

The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.

### top_logprobs
- Type: integer
- Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.

### top_p
- Type: number
- Optional
- Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

### truncation
- Type: string
- Optional
- Defaults to disabled

The truncation strategy to use for the model response.

* `auto`: If the input to this Response exceeds the model's context window size, the model will truncate the response to fit the context window by dropping items from the beginning of the conversation.
* `disabled` (default): If the input size will exceed the context window size for a model, the request will fail with a 400 error.

### user
- Type: string
- Optional
- Deprecated

This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations. A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. [Learn more](/docs/guides/safety-best-practices#safety-identifiers).

## Returns

Returns a [Response](/docs/api-reference/responses/object) object.

## Example requests and responses

### Text input

#### Request

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "input": "Tell me a three sentence bedtime story about a unicorn."
  }'
```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    input: "Tell me a three sentence bedtime story about a unicorn."
});

console.log(response);
```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
  model="gpt-5",
  input="Tell me a three sentence bedtime story about a unicorn."
)

print(response)
```

#### Response

```json
{
  "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
  "object": "response",
  "created_at": 1741476542,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 36,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 87,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 123
  },
  "user": null,
  "metadata": {}
}
```

### Image input

#### Request

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "input": [
      {
        "role": "user",
        "content": [
          {"type": "input_text", "text": "what is in this image?"},
          {
            "type": "input_image",
            "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
          }
        ]
      }
    ]
  }'
```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    input: [
        {
            role: "user",
            content: [
                { type: "input_text", text: "what is in this image?" },
                {
                    type: "input_image",
                    image_url:
                        "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                },
            ],
        },
    ],
});

console.log(response);

```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input=[
        {
            "role": "user",
            "content": [
                { "type": "input_text", "text": "what is in this image?" },
                {
                    "type": "input_image",
                    "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                }
            ]
        }
    ]
)

print(response)

```

#### Response

```json
{
  "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
  "object": "response",
  "created_at": 1741476777,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 52,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 380
  },
  "user": null,
  "metadata": {}
}

```


### File input

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "input": [
      {
        "role": "user",
        "content": [
          {"type": "input_text", "text": "what is in this file?"},
          {
            "type": "input_file",
            "file_url": "https://www.berkshirehathaway.com/letters/2024ltr.pdf"
          }
        ]
      }
    ]
  }'

```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    input: [
        {
            role: "user",
            content: [
                { type: "input_text", text: "what is in this file?" },
                {
                    type: "input_file",
                    file_url: "https://www.berkshirehathaway.com/letters/2024ltr.pdf",
                },
            ],
        },
    ],
});

console.log(response);

```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input=[
        {
            "role": "user",
            "content": [
                { "type": "input_text", "text": "what is in this file?" },
                {
                    "type": "input_file",
                    "file_url": "https://www.berkshirehathaway.com/letters/2024ltr.pdf"
                }
            ]
        }
    ]
)

print(response)

```

#### Response

```json
{
  "id": "resp_686eef60237881a2bd1180bb8b13de430e34c516d176ff86",
  "object": "response",
  "created_at": 1752100704,
  "status": "completed",
  "background": false,
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "max_tool_calls": null,
  "model": "gpt-5",
  "output": [
    {
      "id": "msg_686eef60d3e081a29283bdcbc4322fd90e34c516d176ff86",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "The file seems to contain excerpts from a letter to the shareholders of Berkshire Hathaway Inc., likely written by Warren Buffett. It covers several topics:\n\n1. **Communication Philosophy**: Buffett emphasizes the importance of transparency and candidness in reporting mistakes and successes to shareholders.\n\n2. **Mistakes and Learnings**: The letter acknowledges past mistakes in business assessments and management hires, highlighting the importance of correcting errors promptly.\n\n3. **CEO Succession**: Mention of Greg Abel stepping in as the new CEO and continuing the tradition of honest communication.\n\n4. **Pete Liegl Story**: A detailed account of acquiring Forest River and the relationship with its founder, highlighting trust and effective business decisions.\n\n5. **2024 Performance**: Overview of business performance, particularly in insurance and investment activities, with a focus on GEICO's improvement.\n\n6. **Tax Contributions**: Discussion of significant tax payments to the U.S. Treasury, credited to shareholders' reinvestments.\n\n7. **Investment Strategy**: A breakdown of Berkshire\u2019s investments in both controlled subsidiaries and marketable equities, along with a focus on long-term holding strategies.\n\n8. **American Capitalism**: Reflections on America\u2019s economic development and Berkshire\u2019s role within it.\n\n9. **Property-Casualty Insurance**: Insights into the P/C insurance business model and its challenges and benefits.\n\n10. **Japanese Investments**: Information about Berkshire\u2019s investments in Japanese companies and future plans.\n\n11. **Annual Meeting**: Details about the upcoming annual gathering in Omaha, including schedule changes and new book releases.\n\n12. **Personal Anecdotes**: Light-hearted stories about family and interactions, conveying Buffett's personable approach.\n\n13. **Financial Performance Data**: Tables comparing Berkshire\u2019s annual performance to the S&P 500, showing impressive long-term gains.\n\nOverall, the letter reinforces Berkshire Hathaway's commitment to transparency, investment in both its businesses and the wider economy, and emphasizes strong leadership and prudent financial management."
        }
      ],
      "role": "assistant"
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "service_tier": "default",
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_logprobs": 0,
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 8438,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 398,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 8836
  },
  "user": null,
  "metadata": {}
}

```


### Web search

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "tools": [{ "type": "web_search_preview" }],
    "input": "What was a positive news story from today?"
  }'

```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    tools: [{ type: "web_search_preview" }],
    input: "What was a positive news story from today?",
});

console.log(response);

```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    tools=[{ "type": "web_search_preview" }],
    input="What was a positive news story from today?",
)

print(response)

```

#### Response

```json
{
  "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
  "object": "response",
  "created_at": 1741484430,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "web_search_call",
      "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
      "status": "completed"
    },
    {
      "type": "message",
      "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "As of today, March 9, 2025, one notable positive news story...",
          "annotations": [
            {
              "type": "url_citation",
              "start_index": 442,
              "end_index": 557,
              "url": "https://.../?utm_source=chatgpt.com",
              "title": "..."
            },
            {
              "type": "url_citation",
              "start_index": 962,
              "end_index": 1077,
              "url": "https://.../?utm_source=chatgpt.com",
              "title": "..."
            },
            {
              "type": "url_citation",
              "start_index": 1336,
              "end_index": 1451,
              "url": "https://.../?utm_source=chatgpt.com",
              "title": "..."
            }
          ]
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "web_search_preview",
      "domains": [],
      "search_context_size": "medium",
      "user_location": {
        "type": "approximate",
        "city": null,
        "country": "US",
        "region": null,
        "timezone": null
      }
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 356,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 684
  },
  "user": null,
  "metadata": {}
}

```


### File search

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "tools": [{
      "type": "file_search",
      "vector_store_ids": ["vs_1234567890"],
      "max_num_results": 20
    }],
    "input": "What are the attributes of an ancient brown dragon?"
  }'

```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    tools: [{
      type: "file_search",
      vector_store_ids: ["vs_1234567890"],
      max_num_results: 20
    }],
    input: "What are the attributes of an ancient brown dragon?",
});

console.log(response);

```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    tools=[{
      "type": "file_search",
      "vector_store_ids": ["vs_1234567890"],
      "max_num_results": 20
    }],
    input="What are the attributes of an ancient brown dragon?",
)

print(response)

```

#### Response

```json
{
  "id": "resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7",
  "object": "response",
  "created_at": 1741485253,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "file_search_call",
      "id": "fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7",
      "status": "completed",
      "queries": [
        "attributes of an ancient brown dragon"
      ],
      "results": null
    },
    {
      "type": "message",
      "id": "msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The attributes of an ancient brown dragon include...",
          "annotations": [
            {
              "type": "file_citation",
              "index": 320,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 576,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 815,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 815,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 1030,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 1030,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 1156,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 1225,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            }
          ]
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "file_search",
      "filters": null,
      "max_num_results": 20,
      "ranking_options": {
        "ranker": "auto",
        "score_threshold": 0.0
      },
      "vector_store_ids": [
        "vs_1234567890"
      ]
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 18307,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 348,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 18655
  },
  "user": null,
  "metadata": {}
}      

```


### Streaming

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "instructions": "You are a helpful assistant.",
    "input": "Hello!",
    "stream": true
  }'

```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    instructions: "You are a helpful assistant.",
    input: "Hello!",
    stream: true,
});

for await (const event of response) {
    console.log(event);
}

```

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
  model="gpt-5",
  instructions="You are a helpful assistant.",
  input="Hello!",
  stream=True
)

for event in response:
  print(event)

```

#### Response

```
event: response.created
data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-5","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

event: response.in_progress
data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-5","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

event: response.output_item.added
data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}

event: response.content_part.added
data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}

...

event: response.output_text.done
data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi there! How can I assist you today?"}

event: response.content_part.done
data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}}

event: response.output_item.done
data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}}

event: response.completed
data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-5","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}

```


### Functions

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "input": "What is the weather like in Boston today?",
    "tools": [
      {
        "type": "function",
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"]
            }
          },
          "required": ["location", "unit"]
        }
      }
    ],
    "tool_choice": "auto"
  }'

```

```js
import OpenAI from "openai";

const openai = new OpenAI();

const tools = [
    {
        type: "function",
        name: "get_current_weather",
        description: "Get the current weather in a given location",
        parameters: {
            type: "object",
            properties: {
                location: {
                    type: "string",
                    description: "The city and state, e.g. San Francisco, CA",
                },
                unit: { type: "string", enum: ["celsius", "fahrenheit"] },
            },
            required: ["location", "unit"],
        },
    },
];

const response = await openai.responses.create({
    model: "gpt-5",
    tools: tools,
    input: "What is the weather like in Boston today?",
    tool_choice: "auto",
});

console.log(response);

```

```python
from openai import OpenAI

client = OpenAI()

tools = [
    {
        "type": "function",
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
              "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA",
              },
              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
          },
          "required": ["location", "unit"],
        }
    }
]

response = client.responses.create(
  model="gpt-5",
  tools=tools,
  input="What is the weather like in Boston today?",
  tool_choice="auto"
)

print(response)

```

#### Response

```json
{
  "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
  "object": "response",
  "created_at": 1741294021,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "function_call",
      "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
      "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
      "name": "get_current_weather",
      "arguments": "{\"location\":\"Boston, MA\",\"unit\":\"celsius\"}",
      "status": "completed"
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "function",
      "description": "Get the current weather in a given location",
      "name": "get_current_weather",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {
            "type": "string",
            "description": "The city and state, e.g. San Francisco, CA"
          },
          "unit": {
            "type": "string",
            "enum": [
              "celsius",
              "fahrenheit"
            ]
          }
        },
        "required": [
          "location",
          "unit"
        ]
      },
      "strict": true
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 291,
    "output_tokens": 23,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 314
  },
  "user": null,
  "metadata": {}
}

```


### Reasoning

```curl
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "input": "How much wood would a woodchuck chuck?",
    "reasoning": {
      "effort": "high"
    }
  }'

```

```js
import OpenAI from "openai";
const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-5",
    input: "How much wood would a woodchuck chuck?",
    reasoning: {
      effort: "high"
    }
});

console.log(response);

```

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="How much wood would a woodchuck chuck?",
    reasoning={
        "effort": "high"
    }
)

print(response)

```

#### Response

```json
{
  "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
  "object": "response",
  "created_at": 1741477868,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "o1-2024-12-17",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The classic tongue twister...",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": "high",
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 81,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 1035,
    "output_tokens_details": {
      "reasoning_tokens": 832
    },
    "total_tokens": 1116
  },
  "user": null,
  "metadata": {}
}

```

